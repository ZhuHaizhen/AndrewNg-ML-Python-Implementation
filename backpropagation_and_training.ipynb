{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "C:\\Users\\s\\Downloads\\machine_learning\\machine-learning-ex4\\ex4\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\s\\\\Downloads\\\\machine_learning\\\\machine-learning-ex4\\\\ex4'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "%cd C:\\\\Users\\\\s\\\\Downloads\\\\machine_learning\\\\machine-learning-ex4\\\\ex4\n",
    "%pwd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feedforward and cost function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(5000, 400) (5000, 1)\n(25, 401) (10, 26)\n0.38376985909092365\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "data = loadmat('ex4data1.mat')\n",
    "x0 = data['X']\n",
    "y0 = data['y']\n",
    "print(x0.shape, y0.shape)\n",
    "\n",
    "weights = loadmat('ex4weights.mat')\n",
    "theta1 = weights['Theta1']\n",
    "theta2 = weights['Theta2']\n",
    "print(theta1.shape, theta2.shape)\n",
    "theta0 = np.hstack((theta1.ravel(), theta2.ravel()))\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    return g\n",
    "\n",
    "\n",
    "def nn_cost_function(theta, input_layer_size, hidden_layer_size, num_labels, x, y, lam):\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    weights1 = theta[:hidden_layer_size*(input_layer_size+1)].reshape(hidden_layer_size, input_layer_size+1)\n",
    "    weights2 = theta[hidden_layer_size*(input_layer_size+1):].reshape(num_labels, hidden_layer_size+1)\n",
    "    \n",
    "    y_i = np.zeros((m, num_labels))\n",
    "    for i in range(1, num_labels+1):\n",
    "        y_i[:, i-1] = np.array([1 if label == i else 0 for label in y])\n",
    "    \n",
    "    a1 = np.hstack((np.ones((m, 1)), x))\n",
    "    z2 = a1.dot(weights1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.hstack((np.ones((m, 1)), a2))\n",
    "    z3 = a2.dot(weights2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    cost = y_i * np.log(a3) + (1 - y_i) * np.log(1 - a3)\n",
    "    j = -1 / m * np.sum(cost)\n",
    "    \n",
    "    reg1 = weights1[:, 1:].ravel().dot(weights1[:, 1:].ravel().T)\n",
    "    reg2 = weights2[:, 1:].ravel().dot(weights2[:, 1:].ravel().T)\n",
    "    reg = lam / (2 * m) * (reg1 + reg2)\n",
    "    \n",
    "    j += reg\n",
    "    \n",
    "    return j\n",
    "\n",
    "\n",
    "cost0 = nn_cost_function(theta0, 400, 25, 10, x0, y0, 1)\n",
    "print(cost0)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sigmoid gradient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.25\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    dg = sigmoid(z) * (1 - sigmoid(z))\n",
    "    \n",
    "    return dg\n",
    "\n",
    "\n",
    "print(sigmoid_gradient(0))    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def rand_initialize_weights(l_in, l_out):\n",
    "    epsilon_init = 0.12\n",
    "    w = np.random.rand(l_out, 1+l_in) * 2 * epsilon_init - epsilon_init\n",
    "    \n",
    "    return w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Backpropagation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[ 6.18712766e-05 -2.11248326e-12  4.38829369e-13 ...  4.70513145e-05\n -5.01718610e-04  5.07825789e-04]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def nn_gradient(theta, input_layer_size, hidden_layer_size, num_labels, x, y, lam):\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    weights1 = theta[:hidden_layer_size*(input_layer_size+1)].reshape(hidden_layer_size, input_layer_size+1)\n",
    "    weights2 = theta[hidden_layer_size*(input_layer_size+1):].reshape(num_labels, hidden_layer_size+1)\n",
    "    \n",
    "    y_i = np.zeros((m, num_labels))\n",
    "    for i in range(1, num_labels+1):\n",
    "        y_i[:, i-1] = np.array([1 if label == i else 0 for label in y])\n",
    "    \n",
    "    a1 = np.hstack((np.ones((m, 1)), x))\n",
    "    z2 = a1.dot(weights1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.hstack((np.ones((m, 1)), a2))\n",
    "    z3 = a2.dot(weights2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    delta3 = a3 - y_i\n",
    "    delta2 = delta3.dot(weights2)\n",
    "    delta2 = delta2[:, 1:]\n",
    "    delta2 = delta2 * sigmoid_gradient(z2)\n",
    "    \n",
    "    grad1 = np.zeros(weights1.shape)\n",
    "    grad2 = np.zeros(weights2.shape)\n",
    "\n",
    "    grad1 += delta2.T.dot(a1)\n",
    "    grad2 += delta3.T.dot(a2)\n",
    "    \n",
    "    t1_grad = 1 / m * grad1\n",
    "    t2_grad = 1 / m *grad2\n",
    "    \n",
    "    reg_t1 = lam / m * weights1\n",
    "    reg_t2 = lam / m * weights2\n",
    "    reg_t1[:, 0] = np.zeros(reg_t1.shape[0])\n",
    "    reg_t2[:, 0] = np.zeros(reg_t2.shape[0])\n",
    "    \n",
    "    t1_grad += reg_t1\n",
    "    t2_grad += reg_t2\n",
    "    \n",
    "    grad = np.hstack((t1_grad.ravel(), t2_grad.ravel()))\n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "print(nn_gradient(theta0, 400, 25, 10, x0, y0, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient checking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "6.300716890302574e-10\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def compute_numerical_gradient(theta, input_layer_size, hidden_layer_size, num_labels, x, y, lam):\n",
    "    num_grad = np.zeros(theta.shape)\n",
    "    perturb = np.zeros(theta.shape)\n",
    "    e = 1e-4\n",
    "    \n",
    "    for i in range(theta.shape[0]):\n",
    "        perturb[i] = e\n",
    "        loss1 = nn_cost_function(theta-perturb, input_layer_size, hidden_layer_size, num_labels, x, y, lam)\n",
    "        loss2 = nn_cost_function(theta+perturb, input_layer_size, hidden_layer_size, num_labels, x, y, lam)\n",
    "        num_grad[i] = (np.array(loss2) - np.array(loss1)) / (2 * e)\n",
    "        perturb[i] = 0\n",
    "        \n",
    "    return num_grad\n",
    "\n",
    "\n",
    "def debug_initialize_weights(fan_out, fan_in):\n",
    "    w = np.zeros((fan_out, fan_in+1))\n",
    "    w = np.reshape(np.sin(range(w.size)), w.shape) / 10\n",
    "    \n",
    "    return w\n",
    "\n",
    "\n",
    "def check_nn_gradients(lam):\n",
    "    input_layer_size = 3\n",
    "    hidden_layer_size = 5\n",
    "    num_labels = 3\n",
    "    m = 5\n",
    "    \n",
    "    theta01 = debug_initialize_weights(hidden_layer_size, input_layer_size)\n",
    "    theta02 = debug_initialize_weights(num_labels, hidden_layer_size)\n",
    "    \n",
    "    x = debug_initialize_weights(m, input_layer_size-1)\n",
    "    y = 1 + np.mod([i+1 for i in range(m)], num_labels).T \n",
    "    theta = np.hstack((theta01.ravel(), theta02.ravel()))\n",
    "    \n",
    "    grad = nn_gradient(theta, input_layer_size, hidden_layer_size, num_labels, x, y, lam)\n",
    "    num_grad = compute_numerical_gradient(theta, input_layer_size, hidden_layer_size, num_labels, x, y, lam)\n",
    "    \n",
    "    diff = max((num_grad - grad) / (num_grad + grad))\n",
    "    \n",
    "    return diff\n",
    "\n",
    "\n",
    "print(check_nn_gradients(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Learning parameters using advanced optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "     fun: 0.314143339290856\n     jac: array([-2.97078025e-04, -4.65225049e-08,  4.09766973e-08, ...,\n       -7.15493528e-05, -1.61146109e-04, -1.29273861e-04])\n message: 'Maximum number of iterations has been exceeded.'\n    nfev: 835\n     nit: 400\n    njev: 835\n  status: 1\n success: False\n       x: array([ 1.32908200e-01, -2.32612524e-04,  2.04883486e-04, ...,\n       -1.87567530e+00,  1.41754530e+00,  3.91261043e+00])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 39
    }
   ],
   "source": [
    "params = np.hstack((rand_initialize_weights(400, 25).ravel(), rand_initialize_weights(25, 10).ravel()))\n",
    "res = optimize.minimize(nn_cost_function, x0=params, args=(400, 25, 10, x0, y0, 1), method='CG', jac=nn_gradient, options={'maxiter':400})\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check training result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy: 99.6%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "param1 = res.x[:25 * 401].reshape(25, 401)\n",
    "param2 = res.x[25 * 401:].reshape(10, 26)\n",
    "\n",
    "a01 = np.hstack((np.ones((5000, 1)), x0))\n",
    "a02 = sigmoid(a01.dot(param1.T))\n",
    "a02 = np.hstack((np.ones((5000, 1)), a02))\n",
    "a03 = sigmoid(a02.dot(param2.T))\n",
    "y_pred = np.array(np.argmax(a03, axis=1) + 1)\n",
    "\n",
    "print('Accuracy: {}%'.format(np.mean(y_pred.reshape(-1, 1) == y0) * 100))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}